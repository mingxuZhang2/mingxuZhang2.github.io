---
title: 'Co-Supervised Learning: Improving Weak-to-Strong Generalization with Hierarchical Mixture of Experts'
date: 2024-02-27
permalink: /posts/2024/02/blog-post-2/
tags:
  - Weak-to-strong Generation
  - Scalable Oversight
  - Mixture of Experts
---

有关于CSL论文阅读的一些感悟和笔记。

Main part
======

1. [Co-Supervised Learning: Improving Weak-to-Strong Generalization with Hierarchical Mixture of Experts](https://arxiv.org/pdf/2402.15505.pdf)
    - Motivation: 文章主要聚焦，提出了协助监督学习(Co-Supervised Learning)，实际上就是一个混合专家模型，将问题的Domain进行Decomposition，然后对于每一个Sub-Domain，训练一个专家，这些专家在知识的广度上是不如强学生模型的，但是可能在知识的深度上要好于学生模型，那么在这种情况下，我们通过类似于类增量学习的办法，就可以逐步吸收所有子领域的知识，最终的效果就是一个强学生模型会这个Domain上的所有内容，而老师只精通其中一个领域(类似于高考的各个科目。)
    - Shortcoming：他是在Vision上做了部分实验，包括PGR也是根据ViT来的，在一些文本化的任务，例如代码生成等，推理能力上，都没有一些显著的实验。同时，这篇文章实际上的思想是Incremental Learning，但是实际上没有提出任何关于Incremental Learning的Preliminary，以及也没有讨论Incremental Learning会出现的灾难性遗忘的现象。
    - Inspiration：他最重要的启发就在于，我们的IDA有的时候可以通过增量学习的办法进行描述和求解，同时增量学习中一般会有一些比较好的研究范式和方法来解决灾难性遗忘的现象，这都是有关于IDA可以去做的方向。
    - Metrics:
        - Weak supervision：s是模型在fine-tune(under weak supervision)后的性能，s~是weak-supervisor的表现，s-是模型在某一个数据集上进行fine-tune后的性能upper bound(Ground Truth下的表现)，也叫作强模型的能力恢复，如果PGR=1，说明s=s-。那么就说明我们通过弱监督者监督后模型的表现和当前模型参数所能释放的能力相同，就说明我们weak signal在有效性上和ground Truth相同。
            
            ![Untitled](/image/Paper reading 14a652717cc24eb99932e3cec442bacc/Untitled.png)
            
            ![Untitled](/image/Paper reading 14a652717cc24eb99932e3cec442bacc/Untitled 1.png)
            
            这是文章中有关于PGR的图，是有关于Dino-ViT的Transformer的weak-to-strong的效果图，这个图体现出了PGR和弱模型的能力差距是有关的，当监督者的能力贴近student的时候，PGR的值是最大的。这为下文的Student，Supervisor交替训练奠定了一些基础。
            
    
    - 感觉整体的框架也是很类似于IDA，不过使用了混合专家模型将知识更加具象化，让每一个低参数的Supervisor更加聚焦于某一个领域的知识，然后使用大量的Supervisor达到知识的覆盖性。文章的CSL主要将整体的监督信号进行分级处理，分为K级，然后每一级的监督信号进一步的划分为一系列的Weak Supervisor，下面的图展示了这个过程，是一个两级的监督信号，然后将每一级的监督信号进一步的切割为两个Supervisor进行负责，其中π22同时负责两个Sub-Domain的内容。跟原本的Task Decomposition比，这个类似于Domain-Decomposition，将原本需要大量参数量表示的监督信号切割开，用若干个小型的模型去表示，这样小模型的组合体可以提供原本较大参数才可以提供的监督信号(越说越像IDA)。
    
    ![Untitled](/image/Paper reading 14a652717cc24eb99932e3cec442bacc/Untitled 2.png)
    
    接下来我们可以考虑如何表示出这个监督者，在下面的式子中zk是一个离散变量，代表输入x对应着监督信号的哪一级(k级)，那么这个式子我们可以考虑：在一个大的Supervisor下，我们输入x的条件下，输出p的概率可以看做这个输入信号在z1…zk上的概率乘以在对应域上的输出概率，**这个式子总感觉有点问题呢(这个sigma好突兀)**…但是总体思路就是那样，全概率公式解决。比较困难的一点是zk比较难估计，输入x到底属于哪一级?
    
    ![Untitled](/image/Paper reading 14a652717cc24eb99932e3cec442bacc/Untitled 3.png)
    
    - Training Process：
        - 整体的Pipeline：pai是Weak Supervisor的参数，theta是strong Student的参数，最开始的时候肯定是跟weak-to-strong一样，由π0对theta0进行fine-tune，然后我们考虑实际上，在上面的全概率公式中，我们未知的同时含有最终模型的输出y以及所述的Level zk，我们在下面的范式中可以考虑将学生模型的输出近似为y，然后根据y去估计潜在变量zk的后验分布。这个pipeline首先没有对任何的Supervisor进行更新，迭代的只有学生参数，在这个pipeline中，Supervisor负责提供给学生必要的yk进行SFT，然后学生负责选择最佳的老师，向这个老师学习，蒸馏老师的知识，相当于逐步学习每一个sub-Domain的知识，最后学习到整体问题域的所有知识，这样下来，student的能力要比任意一个teacher的能力都要强。**类增量学习？灾难性遗忘的问题怎么解决？弟子不必不如师，师不必贤于弟子。**
        
        ![Untitled](/image/Paper reading 14a652717cc24eb99932e3cec442bacc/Untitled 4.png)
        
        - Training Details：我们可以计算对应后验概率如3所示，在没有任何知识重叠的前提下，在某一个时间步骤下的参数下，分母为1恒定(全概率公式)，所以我们的潜在变量zk的概率就可以视为分子，所以我们的zk就是分子最大的那个，就有了式4成立。
        
        ![Untitled](/image/Paper reading 14a652717cc24eb99932e3cec442bacc/Untitled 5.png)
        
        ![Untitled](/image/Paper reading 14a652717cc24eb99932e3cec442bacc/Untitled 6.png)
        
        - 对于上述的第一项p(zk|x;πk)，可以用一个简单的分类器实现，或者直接假设所有的分布都是均匀的，我们只需要判定在输入x的情况下，属于知识levelk的概率有多大就可以，这个很好弄，后一项是在当前输入以及Supervisor当前的参数的基础上，输出一个y(学生模型的输出近似为原本的输出)的概率是多少，这个可以直接由Supervisor去提供，所以上面式子是可求解的了。
        - 但是事实上，当前Supervisor输出的y和学生目前输出的y不必要相等，或者说有的时候Supervisor的输出也会对学生产生必要的指导，文章中的例子的意思是强学生模型可能对某个Sub-Domain了解不错，可以做出一些有效的推断，但是缺乏更加精细的内容，但是这部分内容Supervisor是擅长的，所以因此，可以对强学生模型进行fine-tune，用Supervisor的输出y进行fine-tune，下面是时间步K下的参数更新目标。
            
            ![Untitled](/image/Paper reading 14a652717cc24eb99932e3cec442bacc/Untitled 7.png)
            
            下面的式子是我们使用Ground Truth进行SFT的优化目标函数，我们目的是最大化L，上面的式子是我们在CSL的框架下的更新模式，我们在具有数据偏移(label is not ground Truth)下进行更新，我们要最大化在给定prompt x的情况下，输出Supervisor的输出y的概率，这样就做到了在当前时间步下对Supervisor的知识蒸馏。
            
            ![Untitled](/image/Paper reading 14a652717cc24eb99932e3cec442bacc/Untitled 8.png)
            
            接下来我们考虑噪声问题：上面的混合专家模型虽然拥有某一个Sub-Domain的知识，但是其知识量仍然可能较为匮乏，相较于在一个比较丰富的数据集上训练的强Student模型可能仍然较低，那么就可能会存在一定的误导信息，或者叫做误差，如果我们将误差也学习进去，就很有可能出现错误的累积，因为IDA的Amplify不但可以放大知识，同样也可以放大误差，那么在这种情况下，我们就需要将误差抛弃。
            
            ![Untitled](/image/Paper reading 14a652717cc24eb99932e3cec442bacc/Untitled 9.png)
            
            我们考虑measuring误差：我们可以定义*ϵ*为d(y,y~)其正比于d(y^,y~)，d是距离函数，可以通过交叉熵(mse)等进行定义(依据不同的任务可能会有不同的定义)，由于我们不知道真实的y，同样是将学生模型的输出y^近似视为ground truth进行计算，那么我们有了误差之后，我们就可以定义大于多少的误差被舍弃，然后取那些误差不是很大的项目进行选择SFT。
            
        
        ![Untitled](/image/Paper reading 14a652717cc24eb99932e3cec442bacc/Untitled 10.png)