---
title: "Scalable Oversight"
collection: publications
permalink: /publication/Scalable Oversight
excerpt: 'We are working on a project related to Scalable Oversight, focusing on how to enable weak models to cleverly provide necessary supervisory signals to strong models for Weak-to-strong generalization. Our motivation is based on the principle that "criticism is easier than creation." We are currently researching the necessary datasets and preparing for experiments, with the aim of submitting our work to NeurIPS2024.'
type: publication
date: 2024-04-17
flag: 1
venue: 'Expected NeurIPS'
paperurl: 'None'
citation: 'Completing...'
---

We are working on a project related to Scalable Oversight, focusing on how to enable weak models to cleverly provide necessary supervisory signals to strong models for Weak-to-strong generalization. Our motivation is based on the principle that "criticism is easier than creation." We are currently researching the necessary datasets and preparing for experiments, with the aim of submitting our work to NeurIPS2024.We will complete the paper as soon as possible, and once it is finished, we will upload it to Arxiv.

There are some useful links and papers about Scalable Oversight:

- [AI Alignment: A Comprehensive Survey](https://alignmentsurvey.com/)

- [Week 4 - Task decomposition for scalable oversight](https://docs.google.com/document/d/1k6rlyBCZJw8xbUx0dzd-4sOhlzj-xzsmwi_OIZY1-3M/edit?pli=1)

- [Ruiqi's sharing about AI Alignment](https://zhuanlan.zhihu.com/p/655464730)